{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Machine Learning Model\n",
    "Christoph Windheuser, ThoughtWorks, June 19, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.s3 import S3Uploader, S3Downloader\n",
    "import pandas as pd\n",
    "\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import sys, os, json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import joblib\n",
    "sys.path.append(os.path.join('..', 'src'))\n",
    "sys.path.append(os.path.join('src'))\n",
    "from sklearn import tree, ensemble, metrics\n",
    "# import evaluation\n",
    "# import tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Enum):\n",
    "    DECISION_TREE = 0\n",
    "    RANDOM_FOREST = 1\n",
    "    ADABOOST = 2\n",
    "    GRADIENT_BOOST = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training and validation data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_filename = 'store47-2016-train.csv'\n",
    "    test_filename  = 'store47-2016-test.csv'\n",
    "    train_dir      = 'train'\n",
    "    test_dir       = 'test'\n",
    "    local_data_dir = 'data'\n",
    "\n",
    "    sess = boto3.Session()\n",
    "    account_id = sess.client('sts', region_name=sess.region_name).get_caller_identity()[\"Account\"]\n",
    "    bucket = 'sagemaker-studio-{}-{}'.format(sess.region_name, account_id)\n",
    "    prefix = 'demandforecast-rf'\n",
    "\n",
    "    S3Downloader.download('s3://{}/{}/{}/{}'.format(bucket, prefix, train_dir, train_filename),\n",
    "                          '{}/{}'.format(local_data_dir, train_dir))\n",
    "\n",
    "    S3Downloader.download('s3://{}/{}/{}/{}'.format(bucket, prefix, test_dir, test_filename),\n",
    "                          '{}/{}'.format(local_data_dir, test_dir))\n",
    "\n",
    "    train    = pd.read_csv('{}/{}/{}'.format(local_data_dir, train_dir, train_filename), engine='python')\n",
    "    validate = pd.read_csv('{}/{}/{}'.format(local_data_dir, test_dir, test_filename), engine='python')\n",
    "\n",
    "    return train, validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(               id        date  item_nbr  unit_sales            family  class  \\\n",
       " 0        88219279  2016-08-16    103520        10.0         GROCERY I   1028   \n",
       " 1        88219280  2016-08-16    103665         4.0      BREAD/BAKERY   2712   \n",
       " 2        88219281  2016-08-16    105574         9.0         GROCERY I   1045   \n",
       " 3        88219282  2016-08-16    105575        45.0         GROCERY I   1045   \n",
       " 4        88219283  2016-08-16    105577         8.0         GROCERY I   1045   \n",
       " ...           ...         ...       ...         ...               ...    ...   \n",
       " 958778  124019431  2017-08-01   2113914        10.0          CLEANING   3040   \n",
       " 958779  124019432  2017-08-01   2116416        15.0         GROCERY I   1060   \n",
       " 958780  124019433  2017-08-01   2122188         3.0         GROCERY I   1084   \n",
       " 958781  124019434  2017-08-01   2124052         4.0  LIQUOR,WINE,BEER   1318   \n",
       " 958782  124019435  2017-08-01   2127114         3.0         BEVERAGES   1152   \n",
       " \n",
       "         perishable  transactions  year  month  day  dayofweek  \\\n",
       " 0                0          3570  2016      8   16          1   \n",
       " 1                1          3570  2016      8   16          1   \n",
       " 2                0          3570  2016      8   16          1   \n",
       " 3                0          3570  2016      8   16          1   \n",
       " 4                0          3570  2016      8   16          1   \n",
       " ...            ...           ...   ...    ...  ...        ...   \n",
       " 958778           0          3846  2017      8    1          1   \n",
       " 958779           0          3846  2017      8    1          1   \n",
       " 958780           0          3846  2017      8    1          1   \n",
       " 958781           0          3846  2017      8    1          1   \n",
       " 958782           0          3846  2017      8    1          1   \n",
       " \n",
       "         days_til_end_of_data  dayoff  \n",
       " 0                        364   False  \n",
       " 1                        364   False  \n",
       " 2                        364   False  \n",
       " 3                        364   False  \n",
       " 4                        364   False  \n",
       " ...                      ...     ...  \n",
       " 958778                    14   False  \n",
       " 958779                    14   False  \n",
       " 958780                    14   False  \n",
       " 958781                    14   False  \n",
       " 958782                    14   False  \n",
       " \n",
       " [958783 rows x 14 columns],\n",
       "               id        date  item_nbr  unit_sales            family  class  \\\n",
       " 0      124124002  2017-08-02     96995         2.0         GROCERY I   1093   \n",
       " 1      124124003  2017-08-02     99197         1.0         GROCERY I   1067   \n",
       " 2      124124004  2017-08-02    103520         5.0         GROCERY I   1028   \n",
       " 3      124124005  2017-08-02    103665         1.0      BREAD/BAKERY   2712   \n",
       " 4      124124006  2017-08-02    105574        17.0         GROCERY I   1045   \n",
       " ...          ...         ...       ...         ...               ...    ...   \n",
       " 38443  125481864  2017-08-15   2123463         1.0         GROCERY I   1076   \n",
       " 38444  125481865  2017-08-15   2123727         1.0         GROCERY I   1028   \n",
       " 38445  125481866  2017-08-15   2123775         1.0         GROCERY I   1030   \n",
       " 38446  125481867  2017-08-15   2124052        21.0  LIQUOR,WINE,BEER   1318   \n",
       " 38447  125481868  2017-08-15   2126842         2.0         GROCERY I   1030   \n",
       " \n",
       "        perishable  transactions  year  month  day  dayofweek  \\\n",
       " 0               0          3936  2017      8    2          2   \n",
       " 1               0          3936  2017      8    2          2   \n",
       " 2               0          3936  2017      8    2          2   \n",
       " 3               1          3936  2017      8    2          2   \n",
       " 4               0          3936  2017      8    2          2   \n",
       " ...           ...           ...   ...    ...  ...        ...   \n",
       " 38443           0          3581  2017      8   15          1   \n",
       " 38444           0          3581  2017      8   15          1   \n",
       " 38445           0          3581  2017      8   15          1   \n",
       " 38446           0          3581  2017      8   15          1   \n",
       " 38447           0          3581  2017      8   15          1   \n",
       " \n",
       "        days_til_end_of_data  dayoff  \n",
       " 0                        13   False  \n",
       " 1                        13   False  \n",
       " 2                        13   False  \n",
       " 3                        13   False  \n",
       " 4                        13   False  \n",
       " ...                     ...     ...  \n",
       " 38443                     0   False  \n",
       " 38444                     0   False  \n",
       " 38445                     0   False  \n",
       " 38446                     0   False  \n",
       " 38447                     0   False  \n",
       " \n",
       " [38448 rows x 14 columns])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tables(train, validate):\n",
    "    print(\"Joining tables for consistent encoding\")\n",
    "    return train.append(validate).drop('date', axis=1)\n",
    "\n",
    "\n",
    "def encode_categorical_columns(df):\n",
    "    obj_df = df.select_dtypes(include=['object', 'bool']).copy().fillna('-1')\n",
    "    lb = LabelEncoder()\n",
    "    for col in obj_df.columns:\n",
    "        df[col] = lb.fit_transform(obj_df[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "def encode(train, validate):\n",
    "    print(\"Encoding categorical variables\")\n",
    "    train_ids = train.id\n",
    "    validate_ids = validate.id\n",
    "\n",
    "    joined = join_tables(train, validate)\n",
    "\n",
    "    encoded = encode_categorical_columns(joined.fillna(-1))\n",
    "\n",
    "    print(\"Not predicting returns...\")\n",
    "    encoded.loc[encoded.unit_sales < 0, 'unit_sales'] = 0\n",
    "\n",
    "    validate = encoded[encoded['id'].isin(validate_ids)]\n",
    "    train = encoded[encoded['id'].isin(train_ids)]\n",
    "    return train, validate\n",
    "\n",
    "\n",
    "def train_model(train, model=Model.DECISION_TREE, seed=None):\n",
    "    print(\"Training model using regressor: {}\".format(model.name))\n",
    "    train_dropped = train.drop('unit_sales', axis=1)\n",
    "    target = train['unit_sales']\n",
    "\n",
    "    if model == Model.RANDOM_FOREST:\n",
    "        params = {'n_estimators': 10}\n",
    "        clf = ensemble.RandomForestRegressor(random_state=seed, **params)\n",
    "    elif model == Model.ADABOOST:\n",
    "        params = {'n_estimators': 50, 'learning_rate': 1.0, 'loss':'linear'}\n",
    "        clf = ensemble.AdaBoostRegressor(random_state=seed, **params)\n",
    "    elif model == Model.GRADIENT_BOOST:\n",
    "        params = {'n_estimators': 200, 'max_depth': 4}\n",
    "        clf = ensemble.GradientBoostingRegressor(random_state=seed, **params)\n",
    "    else:\n",
    "        params = {'criterion': 'mse'}\n",
    "        clf = tree.DecisionTreeRegressor(random_state=seed)\n",
    "\n",
    "    trained_model = clf.fit(train_dropped, target)\n",
    "    return (trained_model,params)\n",
    "\n",
    "\n",
    "def overwrite_unseen_prediction_with_zero(preds, train, validate):\n",
    "    cols_item_store = ['item_nbr', 'store_nbr']\n",
    "    cols_to_use = validate.columns.drop('unit_sales') if 'unit_sales' in validate.columns else validate.columns\n",
    "    validate_train_joined = pd.merge(validate[cols_to_use], train, on=cols_item_store, how='left')\n",
    "    unseen = validate_train_joined[validate_train_joined['unit_sales'].isnull()]\n",
    "    validate['preds'] = preds\n",
    "    validate.loc[validate.id.isin(unseen['id_x']), 'preds'] = 0\n",
    "    preds = validate['preds'].tolist()\n",
    "    return preds\n",
    "\n",
    "\n",
    "def make_predictions(model, validate):\n",
    "    print(\"Making prediction on validation data\")\n",
    "    validate_dropped = validate.drop('unit_sales', axis=1).fillna(-1)\n",
    "    validate_preds = model.predict(validate_dropped)\n",
    "    return validate_preds\n",
    "\n",
    "\n",
    "def write_predictions_and_score(evaluation_metrics, model, columns_used):\n",
    "    key = \"decision_tree\"\n",
    "    if not os.path.exists('data/{}'.format(key)):\n",
    "        os.makedirs('data/{}'.format(key))\n",
    "    filename = 'data/{}/model.pkl'.format(key)\n",
    "    print(\"Writing to {}\".format(filename))\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "    filename = 'results/metrics.json'\n",
    "    print(\"Writing to {}\".format(filename))\n",
    "    if not os.path.exists('results'):\n",
    "        os.makedirs('results')\n",
    "    with open(filename, 'w+') as score_file:\n",
    "        json.dump(evaluation_metrics, score_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model=Model.DECISION_TREE, seed=None):\n",
    "    original_train, original_validate = load_data()\n",
    "    train, validate = encode(original_train, original_validate)\n",
    "    with tracking.track() as track:\n",
    "        track.set_model(model)\n",
    "        model, params = train_model(train, model, seed)\n",
    "        track.log_params(params)\n",
    "        validation_predictions = make_predictions(model, validate)\n",
    "\n",
    "        print(\"Calculating metrics\")\n",
    "        evaluation_metrics = {\n",
    "            'nwrmsle': evaluation.nwrmsle(validation_predictions, validate['unit_sales'].values, validate['perishable'].values),\n",
    "            'r2_score': metrics.r2_score(y_true=validate['unit_sales'].values, y_pred=validation_predictions)\n",
    "        }\n",
    "        track.log_metrics(evaluation_metrics)\n",
    "\n",
    "        write_predictions_and_score(evaluation_metrics, model, original_train.columns)\n",
    "\n",
    "        print(\"Evaluation done with metrics {}.\".format(json.dumps(evaluation_metrics)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical variables\n",
      "Joining tables for consistent encoding\n",
      "Not predicting returns...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tracking' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7be9a5464c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRANDOM_FOREST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8675309\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-ee06def0bd30>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(model, seed)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0moriginal_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_validate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_validate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tracking' is not defined"
     ]
    }
   ],
   "source": [
    "main(model=Model.RANDOM_FOREST, seed=8675309)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
