{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and split raw data into training and test data    \n",
    "Christoph Windheuser, ThoughtWorks, June 19, 2020    \n",
    "     \n",
    "This notebook needs to be run in SageMaker Studio. It reads the data as csv-file from a public S3 bucket. Then it splits the data into a training and a test set and saves all in a personal S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary libraries    \n",
    "pandas is a python data science library to handle dataframes    \n",
    "boto3 is the Amazon Web Services SDK for Python. It enables Python developers to create, configure, and manage AWS services, such as EC2 and S3.    \n",
    "S3Uploader and S3Downloader are routines to upload or download data into S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from   sklearn.preprocessing import LabelEncoder\n",
    "import boto3\n",
    "from   sagemaker.s3 import S3Uploader, S3Downloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename   = 'store47-2016-train.csv'\n",
    "test_filename    = 'store47-2016-test.csv'\n",
    "final_train_file = 'final_train.csv'\n",
    "final_test_file  = 'final_validate.csv'\n",
    "local_data_dir   = 'CD4ML-AWS-Serverless/data'\n",
    "local_tmp_dir    = 'CD4ML-AWS-Serverless/data/tmp'\n",
    "s3_prefix        = 'demandforecast'\n",
    "raw_filename     = 'store47-2016.csv'\n",
    "s3_raw_data_path = 'https://christoph-windheuser-public.s3.amazonaws.com'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 10)         # Keep the output on one page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define write_df_to_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_to_s3(df, filename, s3_path):\n",
    "    if not os.path.exists(local_tmp_dir):\n",
    "        os.makedirs(local_tmp_dir)\n",
    "    df.to_csv('{}/{}'.format(local_tmp_dir, filename), index=False)\n",
    "    s3url = S3Uploader.upload('{}/{}'.format(local_tmp_dir, filename), s3_path)\n",
    "    os.remove('{}/{}'.format(local_tmp_dir, filename))\n",
    "    print(s3url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define write_dic_to_json_to_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dic_to_json_to_s3(dic, filename, s3_path):\n",
    "    if not os.path.exists(local_tmp_dir):\n",
    "        os.makedirs(local_tmp_dir)\n",
    "    \n",
    "    with open('{}/{}'.format(local_tmp_dir, filename), 'w') as fp:\n",
    "        json.dump(dic, fp)\n",
    "        \n",
    "    s3url = S3Uploader.upload('{}/{}'.format(local_tmp_dir, filename), s3_path)\n",
    "    os.remove('{}/{}'.format(local_tmp_dir, filename))\n",
    "    print(s3url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Open S3 Session and define Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess       = boto3.Session()\n",
    "account_id = sess.client('sts', region_name=sess.region_name).get_caller_identity()[\"Account\"]\n",
    "bucket     = 'sagemaker-studio-{}-{}'.format(sess.region_name, account_id)\n",
    "\n",
    "try:\n",
    "    if sess.region_name == \"us-east-1\":\n",
    "        sess.client('s3').create_bucket(Bucket=bucket)\n",
    "    else:\n",
    "        sess.client('s3').create_bucket(Bucket=bucket, \n",
    "                                        CreateBucketConfiguration={'LocationConstraint': sess.region_name})\n",
    "except Exception as e:\n",
    "    print(\"Looks like you already have a bucket of this name. That's good. Uploading the data files...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read raw data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('{}/{}'.format(s3_raw_data_path, raw_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>transactions</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>days_til_end_of_data</th>\n",
       "      <th>dayoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88219279</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>103520</td>\n",
       "      <td>10.0</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88219280</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>103665</td>\n",
       "      <td>4.0</td>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88219281</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>105574</td>\n",
       "      <td>9.0</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88219282</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>105575</td>\n",
       "      <td>45.0</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88219283</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>105577</td>\n",
       "      <td>8.0</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88219284</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>105693</td>\n",
       "      <td>2.0</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1034</td>\n",
       "      <td>0</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>88219285</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>105737</td>\n",
       "      <td>6.0</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1044</td>\n",
       "      <td>0</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>88219286</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>105857</td>\n",
       "      <td>14.0</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1092</td>\n",
       "      <td>0</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>88219287</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>106716</td>\n",
       "      <td>13.0</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>88219288</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>108079</td>\n",
       "      <td>2.0</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1030</td>\n",
       "      <td>0</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id        date  item_nbr  unit_sales        family  class  \\\n",
       "0  88219279  2016-08-16    103520        10.0     GROCERY I   1028   \n",
       "1  88219280  2016-08-16    103665         4.0  BREAD/BAKERY   2712   \n",
       "2  88219281  2016-08-16    105574         9.0     GROCERY I   1045   \n",
       "3  88219282  2016-08-16    105575        45.0     GROCERY I   1045   \n",
       "4  88219283  2016-08-16    105577         8.0     GROCERY I   1045   \n",
       "5  88219284  2016-08-16    105693         2.0     GROCERY I   1034   \n",
       "6  88219285  2016-08-16    105737         6.0     GROCERY I   1044   \n",
       "7  88219286  2016-08-16    105857        14.0     GROCERY I   1092   \n",
       "8  88219287  2016-08-16    106716        13.0     GROCERY I   1032   \n",
       "9  88219288  2016-08-16    108079         2.0     GROCERY I   1030   \n",
       "\n",
       "   perishable  transactions  year  month  day  dayofweek  \\\n",
       "0           0          3570  2016      8   16          1   \n",
       "1           1          3570  2016      8   16          1   \n",
       "2           0          3570  2016      8   16          1   \n",
       "3           0          3570  2016      8   16          1   \n",
       "4           0          3570  2016      8   16          1   \n",
       "5           0          3570  2016      8   16          1   \n",
       "6           0          3570  2016      8   16          1   \n",
       "7           0          3570  2016      8   16          1   \n",
       "8           0          3570  2016      8   16          1   \n",
       "9           0          3570  2016      8   16          1   \n",
       "\n",
       "   days_til_end_of_data  dayoff  \n",
       "0                   364   False  \n",
       "1                   364   False  \n",
       "2                   364   False  \n",
       "3                   364   False  \n",
       "4                   364   False  \n",
       "5                   364   False  \n",
       "6                   364   False  \n",
       "7                   364   False  \n",
       "8                   364   False  \n",
       "9                   364   False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data at the date 2017-08-02 (last 14 days of data set)\n",
    "data_train = data[data['date'] < '2017-08-02']\n",
    "data_test  = data[data['date'] >= '2017-08-02']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save train and test data as csv-file to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, save files locally on the SageMaker instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-studio-us-east-1-261586618408/demandforecast/train/store47-2016-train.csv\n",
      "s3://sagemaker-studio-us-east-1-261586618408/demandforecast/test/store47-2016-test.csv\n"
     ]
    }
   ],
   "source": [
    "write_df_to_s3(data_train, train_filename, 's3://{}/{}/{}'.format(bucket, s3_prefix,'train'))\n",
    "write_df_to_s3(data_test,  test_filename,  's3://{}/{}/{}'.format(bucket, s3_prefix,'test'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Encode non-numerical values and drop date column\n",
    "The encoding schema of the product families is written to the json-file \"family_encoder.json\", as this encoding is later necessary in the ML model for inference. This file is written to S3 into the directory \"train/final/\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tables(train, validate):\n",
    "    print(\"Joining tables for consistent encoding\")\n",
    "    return train.append(validate).drop('date', axis=1)\n",
    "\n",
    "\n",
    "def encode_categorical_columns(df):\n",
    "    obj_df = df.select_dtypes(include=['object', 'bool']).copy().fillna('-1')\n",
    "    lb = LabelEncoder()\n",
    "    classes_dic = {}\n",
    "    \n",
    "    for col in obj_df.columns:\n",
    "        print (col)\n",
    "        df[col] = lb.fit_transform(obj_df[col])\n",
    "\n",
    "        if col == \"family\":    \n",
    "            classes = list(lb.classes_)\n",
    "            for index, c in enumerate(classes):\n",
    "                classes_dic[c] = index\n",
    "            write_dic_to_json_to_s3(classes_dic, 'family_encoder.json', 's3://{}/{}/{}'.format(bucket, s3_prefix,'train/final'))\n",
    "\n",
    "            # print (classes_dic)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def encode(train, validate):\n",
    "    print(\"Encoding categorical variables\")\n",
    "    train_ids = train.id\n",
    "    validate_ids = validate.id\n",
    "\n",
    "    joined  = join_tables(train, validate)\n",
    "\n",
    "    encoded = encode_categorical_columns(joined.fillna(-1))\n",
    "\n",
    "    print(\"Not predicting returns (changing negative unit sales to 0)\")\n",
    "    encoded.loc[encoded.unit_sales < 0, 'unit_sales'] = 0\n",
    "\n",
    "    validate = encoded[encoded['id'].isin(validate_ids)]\n",
    "    train = encoded[encoded['id'].isin(train_ids)]\n",
    "    return train, validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical variables\n",
      "Joining tables for consistent encoding\n",
      "family\n",
      "s3://sagemaker-studio-us-east-1-261586618408/demandforecast/train/final/family_encoder.json\n",
      "dayoff\n",
      "Not predicting returns (changing negative unit sales to 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>transactions</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>days_til_end_of_data</th>\n",
       "      <th>dayoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88219279</td>\n",
       "      <td>103520</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88219280</td>\n",
       "      <td>103665</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88219281</td>\n",
       "      <td>105574</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88219282</td>\n",
       "      <td>105575</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88219283</td>\n",
       "      <td>105577</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "      <td>3570</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  item_nbr  unit_sales  family  class  perishable  transactions  \\\n",
       "0  88219279    103520        10.0      11   1028           0          3570   \n",
       "1  88219280    103665         4.0       4   2712           1          3570   \n",
       "2  88219281    105574         9.0      11   1045           0          3570   \n",
       "3  88219282    105575        45.0      11   1045           0          3570   \n",
       "4  88219283    105577         8.0      11   1045           0          3570   \n",
       "\n",
       "   year  month  day  dayofweek  days_til_end_of_data  dayoff  \n",
       "0  2016      8   16          1                   364       0  \n",
       "1  2016      8   16          1                   364       0  \n",
       "2  2016      8   16          1                   364       0  \n",
       "3  2016      8   16          1                   364       0  \n",
       "4  2016      8   16          1                   364       0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate = encode(data_train, data_test)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>transactions</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>days_til_end_of_data</th>\n",
       "      <th>dayoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958783</th>\n",
       "      <td>124124002</td>\n",
       "      <td>96995</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "      <td>3936</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958784</th>\n",
       "      <td>124124003</td>\n",
       "      <td>99197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "      <td>3936</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958785</th>\n",
       "      <td>124124004</td>\n",
       "      <td>103520</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "      <td>3936</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958786</th>\n",
       "      <td>124124005</td>\n",
       "      <td>103665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "      <td>3936</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958787</th>\n",
       "      <td>124124006</td>\n",
       "      <td>105574</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "      <td>3936</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  item_nbr  unit_sales  family  class  perishable  \\\n",
       "958783  124124002     96995         2.0      11   1093           0   \n",
       "958784  124124003     99197         1.0      11   1067           0   \n",
       "958785  124124004    103520         5.0      11   1028           0   \n",
       "958786  124124005    103665         1.0       4   2712           1   \n",
       "958787  124124006    105574        17.0      11   1045           0   \n",
       "\n",
       "        transactions  year  month  day  dayofweek  days_til_end_of_data  \\\n",
       "958783          3936  2017      8    2          2                    13   \n",
       "958784          3936  2017      8    2          2                    13   \n",
       "958785          3936  2017      8    2          2                    13   \n",
       "958786          3936  2017      8    2          2                    13   \n",
       "958787          3936  2017      8    2          2                    13   \n",
       "\n",
       "        dayoff  \n",
       "958783       0  \n",
       "958784       0  \n",
       "958785       0  \n",
       "958786       0  \n",
       "958787       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Save train and test data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-studio-us-east-1-261586618408/demandforecast/train/final/final_train.csv\n",
      "s3://sagemaker-studio-us-east-1-261586618408/demandforecast/test/final/final_validate.csv\n"
     ]
    }
   ],
   "source": [
    "write_df_to_s3(train,    final_train_file, 's3://{}/{}/{}'.format(bucket, s3_prefix,'train/final'))\n",
    "write_df_to_s3(validate, final_test_file,  's3://{}/{}/{}'.format(bucket, s3_prefix,'test/final'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
